#### 进制表示
```javascript
let a = 0b10100; // 二进制用0b表示 20
console.log(a);
let b = 0o24; // 8进制0o表示 20
console.log(b);
let c = 24; // 10进制表示 20
console.log(c);
let d = 0x14; // 16进制0x表示 20
console.log(d);
// NOTE 将任意进制转为10进制，parseInt的第一个参数为字符串
console.log(parseInt('0x10', 16)); // 将16进制的'0x10'字符串转为10进制得16
// NOTE 将10进制转为任意进制
console.log((20).toString(16)); // 将十进制的20转为16进制得'14'字符
```

#### 编码格式
##### ASCII码
> 美国人发明的编码格式，用一个8位字节表示，能够表示256(11111111 -> 2^7+2^6+2^5+2^4+2^3+2^2+2^4+2^0+ -> 2^8-1)个状态，ASCII只使用了127位

在ASCII中，**0-32**中状态规定了**特殊用途**，如：`0x10(->16)`表示终端换行，又把所有的空格，标点符号，数字，大小写字母分别用连学的自解状态表示，一直用到了**127位**，这样这**128(0-127包含32个不能打印出来的控制符号)**，只占用了一个字节的后面7位(01111111 -> 127)，前面统一规定为0；ASCII表如下：
![ASCII](./ascii.jpg)
后来一些其他西欧国家用的不是英文，所以他们就直接用了127号之后的空位来保存他们新的字母，一直保存到255，所以128-255这一页的字符集被称为扩展字符集

##### G(国)B(标)2312
> 中国为了表示汉字，把127号之后的符号取消了，使用了俩个字节来表示汉字。GB2312是对ASCII编码的中文扩展，可以组合出7000多个**简体**汉字,其中有一部分未使用
其中规定：
- 一个小于127的字符的意义与原来的相同，但两个大于127的字符连在一起，就表示一个汉字；
- 前面一个称之为高字节(247-161)(**大于127**)，后面一个成为低字节(254-161)(**大于127**)；
- 还把数字符号，日文假名和ASCII里原来就有的数字、标点和字母都重新编程俩个字长的编码，这就是全角字符，127以下的那些就叫做半角字符；

##### G(国)B(标)K(扩展)
> 后来还是不够用，干脆就等于低位不做**大于127**的限制，只要一个字节是大于127就认为是一个汉字的开始。这样就又增加了近20000个字符，包含繁体字和符号，就成为了GBK编码

##### G(国)B(标)18030 / DBCS
> 增加了几千个新的少数民族的字，GBK扩展成为了GB18030,通称DBCS

##### Unicode(简称UCS，俗称为Unicode)
> ISO的国际组织定制的一个包括了地球上所有文化、所有字母和符号的编码。Unicode是一个很大集合，现在的规模可以容纳100多万个符号。
直接使用俩个字节，也就是16位来统一表示所有字符，对于ASCII里的那些半角字符，Unicode保持其原编码不变，只会将其长度由原来的8位扩展为16位，而其他文化和语言则全部统一编码。
从Unicode开始，无乱世半角的英文字母还是全角的汉字，他们都是统一的一个字符。也是统一的俩个字节。
- 字节是8位的物理存储单元。
- 字符则是一个文化相关的符号。

##### UTF-8
> 但Unicode在很长一段时间都是无法推广，直到互联网的出现，为解决Unicode如何在网络上传输存储的问题，于是面向传输的众多UTF标准出现了，UTF-8就是使用最广的一种Unicode实现和存储方式之一。
- UTF-8每次都是以8个位为单位传输数据
- UTF-16就是每次以16个位传输  
- UTF-8最大的一个特点就是他是一种变长的编码方式，在表示英文字符(1个字节)和中文字符(3个字节)时，所占用的字节数是不一样的。
- Unicode是一个中文字符占2个字节，而UTF-8一个中文字符占3个字节
- 编码规则：
    1. 对于单字节的符号，第一位设为0，后面7位表示这个符号的Unicode，因为对于英文字母，UTF-8和ASCII码是相同的。吧

###### 联通不如移动
在中文的windows的记事本当中，默认采用的是本地编码`ANSI(GB2312/GBK)`编码，而输入`联通`时，记事本会将在解析`联通`二进制码时，错误的将其判定为`UTF-8`编码格式。导致再次打开时为乱码。
**原因**：
1. 联：

C1 1100 0001

AA 1010 1010
2. 通：

CD 1100 1101

AB 1010 1000

这俩个字在GB2312中的二进制码与UTF-8所保留的110*，10*一致，导致记事本错误的猜测应该采用UTF-8编码，所以导致错误！

#### base64
> base64的编码是将二进制编码为字符串，与其他编码方法将二进制转为字符串相反；

> base64是为了解决非纯英文在传输时出现的乱码情况。如中文或其他文字传输， 还有非文字类的，如图片等二进制传输；

##### 编码：
base64在编码时，是根据`['A', 'B', 'C', ... 'a', 'b', 'c', ... '0', '1', ... '+', '/']`来进行匹配，具体步骤为：
1. 将待转换的字符或者二进制分为每`3字节`一组，一共`3 * 8 = 24`位，然后将每6位组合一起，分为4组，`4 * 6 = 24`位；**之所以要每6位组合，是因为6位二进制`111111`转为十进制就是63，那么从0-63也就刚好够进行匹配；**；
2. 将每组6位前面添加2个0，组成4个8位，也就是4个字节，所以**3个字节变成了4个字节，base64编码方式就会比让原来字符所占的二进制大三分之一左右**；
3. 再根据每个组合二进制算出来的十进制数去匹配，最后组合在一起，

![例子](https://img-blog.csdnimg.cn/20190517212249969.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9oZWxsby5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)
- 第一步：“M”、“a”、"n"对应的ASCII码值分别为77，97，110，对应的二进制值是01001101、01100001、01101110。如图第二三行所示，由此组成一个24位的二进制字符串。
- 第二步：如图红色框，将24位每6位二进制位一组分成四组。
- 第三步：在上面每一组前面补两个0，扩展成32个二进制位，此时变为四个字节：00010011、00010110、00000101、00101110。分别对应的值（Base64编码索引）为：19、22、5、46。
- 第四步：用上面的值在Base64编码表中进行查找，分别对应：T、W、F、u。因此“Man”Base64编码之后就变为：TWFu。

##### 注意事项
- base64在将每3个字节分组时。如果不足以组成3个字节，那么如下处理：
![图片](https://img-blog.csdnimg.cn/20190517212307382.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9oZWxsby5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)
    1. 两个字节：两个字节共16个二进制位，依旧按照规则进行分组。此时总共16个二进制位，每6个一组，则第三组缺少2位，用0补齐，得到三个Base64编码，第四组完全没有数据则用“=”补上。因此，上图中“BC”转换之后为“QKM=”；
    2. 一个字节：一个字节共8个二进制位，依旧按照规则进行分组。此时共8个二进制位，每6个一组，则第二组缺少4位，用0补齐，得到两个Base64编码，而后面两组没有对应数据，都用“=”补上。因此，上图中“A”转换之后为“QQ==”；
- Base64编码主要用在传输、存储、表示二进制领域，不能算得上加密，只是无法直接看到明文。也可以通过打乱Base64编码来进行加密。
- 中文有多种编码（比如：utf-8、gb2312、gbk等），不同编码对应Base64编码结果都不一样。
- 上面我们已经看到了Base64就是用6位（2的6次幂就是64）表示字符，因此成为Base64。同理，Base32就是用5位，Base16就是用4位。

